\documentclass{article}

\usepackage{longtable}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{longtable}
\usepackage{booktabs}
\begin{document}
\title{Uncertainty Definitions and Bayesian Representation (AU, EU, TU)}
\author{Expert Response}
\date{\today}
\maketitle

\begin{abstract}
This document provides the definitions of Aleatoric Uncertainty (AU), Epistemic Uncertainty (EU), and Total Uncertainty (TU), detailing their theoretical Bayesian representation and practical modeling, particularly within the context of Explainable Artificial Intelligence (XAI).
\end{abstract}

\section{Definitions of AU, EU, and TU}

Uncertainty quantification (UQ) aims to provide a reliable representation of a model's limitations by distinguishing between two fundamental sources of uncertainty: Aleatoric and Epistemic Uncertainty \cite{SH25, THIES25}.

\begin{longtable}{p{0.1\linewidth} p{0.25\linewidth} p{0.65\linewidth}}
\caption{Definitions of Uncertainty Types} \\
\toprule
\textbf{Term} & \textbf{Full Name} & \textbf{Definition and Characteristics} \\
\midrule
\endhead
\bottomrule
\endfoot
\textbf{TU} & \textbf{Total Uncertainty} & This is the aggregate predictive uncertainty, encompassing both sources of error \cite{SH25, THIES25}. \\
\midrule
\textbf{AU} & \textbf{Aleatoric Uncertainty} (Data Uncertainty) & Arises from the inherent stochasticity, noise, or randomness within the data generating process itself \cite{SH25, THIES25}. It reflects the non-deterministic relationship between input and output \cite{SH25, THIES25}. It is generally considered \textbf{irreducible} by observing more examples of the phenomenon, although gathering more features might alleviate it \cite{SH25, THIES25}. \\
\midrule
\textbf{EU} & \textbf{Epistemic Uncertainty} (Model Uncertainty) & Stems from the learning algorithm's ignorance of the true underlying model \cite{SH25, THIES25}. It relates to \textbf{model multiplicity}, where multiple models can achieve similar performance \cite{SH25}. It is potentially \textbf{reducible} by acquiring additional data or observations, thereby training the model more reliably \cite{SH25, THIES25}. \\
\end{longtable}

\section{Theoretical Representation using Bayesian Methods}

Bayesian learning provides the fundamental framework for representing and decomposing uncertainty by assuming a probability distribution over model parameters $\Theta$, leading to predictive distributions $p(y|x)$ \cite{SH25, THIES25}.

The decomposition of Total Uncertainty (TU) relies on quantifying the uncertainty based on the shape of the output distribution (first-order distribution) and the distribution over those outputs (second-order distribution) \cite{SH25, THIES25}.

\subsection{Classification (Using Shannon Entropy, $H_S$)}
When measuring uncertainty for classification using Shannon Entropy, $H_S[p(y|x)]$, the theoretical decomposition into Aleatoric Uncertainty (AUS) and Epistemic Uncertainty (EUS) is based on the relationship between model variance and intrinsic data noise. The total uncertainty is decomposed as follows\cite{SH25, THIES25}:

\begin{align*}
\textnormal{TU}(x) = H_S [p(y|x)] &= \underbrace{\mathbb{E}_{\Theta}[H_S [p(y|x, \theta)]]}_{\text{Aleatoric Uncertainty (AUS)}} + \underbrace{\mathbb{E}_{p(y,\theta\mid x)}\left[\log\left(\frac{p(y\mid x)\,p(\theta\mid x)}{p(y,\theta\mid x)}\right)\right]}_{\text{Epistemic Uncertainty (EUS)}}
\end{align*}


\begin{itemize}
    \item \textbf{AUS} represents the expected entropy of the predictive distribution over the posterior distribution of the parameters. Since a fixed set of parameters $\theta$ eliminates model uncertainty, the remaining uncertainty is purely due to irreducible data noise \cite{SH25, THIES25}.
    \item \textbf{EUS} captures the uncertainty resulting from ignorance about the true parameters $\Theta$ \cite{SH25, THIES25}. It is calculated as the difference: $EUS(x) = H_S(x) - AUS(x)$ \cite{SH25, THIES25}.
\end{itemize}

\subsection{Regression (Using Variance, $H_V$)}
For regression tasks, total uncertainty is quantified using variance, $H_V(x) = V_Y[y|x]$. The decomposition is based on the law of total variance:
\begin{align*}
H_V(x) &= \underbrace{E_{\Theta}[V_Y[y|x, \theta]]}_{\text{Aleatoric Uncertainty (AUV)}} + \underbrace{V_{\Theta}[E_Y[y|x, \theta]]}_{\text{Epistemic Uncertainty (EUV)}}
\end{align*}
\begin{itemize}
    \item \textbf{AUV} (Aleatoric Variance) measures the expected variance of the outcome given the model parameters, reflecting irreducible noise \cite{SH25, THIES25}.
    \item \textbf{EUV} (Epistemic Variance) measures the variance of the mean outputs across different sampled parameters, reflecting the model's uncertainty about its optimal parameters \cite{SH25, THIES25}.
\end{itemize}

\section{Practical Modelling using Bayesian Neural Networks}

In practice, full Bayesian inference is often intractable, so approximations, typically using \textbf{Bayesian Neural Networks (BNNs)} or ensembles thereof, are employed to quantify uncertainty \cite{SH25, THIES25, SCHUT2021}. This involves drawing a finite sample of weights $\{\theta_1, \ldots, \theta_n\}$ from the approximate posterior distribution \cite{SH25}.

\subsection{Practical Quantification using Finite Samples}

When dealing with a finite sample of model predictions $p(y|\theta_i, x)$, the uncertainties are computed as follows:

\begin{longtable}{p{0.25\linewidth} p{0.75\linewidth}}
\caption{Practical Uncertainty Formulas (Finite Sample)} \\
\toprule
\textbf{Uncertainty Type} & \textbf{Formula (Classification using Entropy / Regression using Variance)} \\
\midrule
\endhead
\bottomrule
\endfoot
\textbf{Aleatoric Uncertainty (AU)} & $\textnormal{AUS}(x) = -\frac{1}{n} \sum_{i=1}^n \left( \sum_{y \in Y} p(y|\theta_i, x) \log_2 p(y|\theta_i, x) \right)$ (Average Entropy) \\
 & $\textnormal{AUV}(x) = \frac{1}{n} \sum_{i=1}^n \sigma_i^2$ (Average Variance of output distribution) \cite{SH25, THIES25} \\
\midrule
\textbf{Epistemic Uncertainty (EU)} & $\textnormal{EUS}(x) = \textnormal{TUS}(x) - \textnormal{AUS}(x)$ \\
 & $\textnormal{EUV}(x) = \frac{1}{n} \sum_{i=1}^n (\mu_i - \mu^*)^2$ (Variance of the predicted means) \cite{SH25, THIES25} \\
\midrule
\textbf{Total Uncertainty (TU)} & $\textnormal{TUS}$ is the entropy computed from the averaged probability distribution $\frac{1}{n}\sum_{i=1}^n p(y|\theta_i, x)$. \\
 & $\textnormal{TUV}(x) = \textnormal{AUV}(x) + \textnormal{EUV}(x)$. \\
\end{longtable}

\subsection{Application in Counterfactual Explanations (CE)}

Uncertainty quantification provides a unifying framework for generating Counterfactual Explanations (CE) by linking uncertainty measures to desirable CE properties \cite{SH25, THIES25}. Approaches like CLUE (Counterfactual Latent Uncertainty Explanations) embed uncertainty minimization into the explanation generation objective \cite{LK21, THIES25, SCHUT2021}.

\begin{itemize}
    \item \textbf{Minimizing AU for Validity and Discriminativeness:} Low AU means the inherent data noise is low, ensuring the resulting counterfactual $x^{CF}$ is confidently classified into the target class $\tau$ (Validity) and is unambiguously separable from other classes (Discriminativeness) \cite{SH25, THIES25, THIES25}.
    \item \textbf{Minimizing EU for Plausibility and Feasibility:} Low EU means the model is certain about its prediction at $x^{CF}$. Points far from the training data manifold exhibit high EU, so minimizing EU guides the counterfactual toward the observed data distribution (Plausibility/Feasibility) \cite{SH25, THIES25}.
\end{itemize}

The objective functions for finding CEs often utilize optimization (OPT) strategies \cite{GUI24, MOC2025} or Multi-Objective Optimization (MOO) \cite{DANDL2020, KINJO2025, MOC2025}. A general optimization loss function $\mathcal{L}(x^{CF})$ often combines prediction certainty (Validity) and distance \cite{BULIGA2025}:

\begin{align*}
\mathcal{L}(x^{CF}) = \underbrace{\mathcal{H}(y|\mu_{\Theta}(x|z))}_{\text{Uncertainty/Validity measure}} + \underbrace{d(\mu_{\Theta}(x|z), x_0)}_{\text{Distance metric}}
\end{align*}

In multi-objective optimization, a counterfactual search problem aims to minimize multiple functions simultaneously \cite{KINJO2025, DANDL2020}:
$$\min_{\theta\in C} F(\theta), \quad\text{where}\quad F(\theta)=\left(F_{1}(\theta),F_{2}(\theta),\dots,F_{L}(\theta)\right)$$
where $F_L(\theta)$ represents $L$ objectives, such as minimizing cost (distance) and ensuring high predictive validation, potentially across multiple models (model multiplicity) \cite{KINJO2025}.

\bibliographystyle{plain}
\bibliography{refs}
\end{document}